{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 1 - Question 2\n",
    "\n",
    "## Web References\n",
    "\n",
    "- [k-means document clustering using Apache Mahout command line](https://datasciencetutos.wordpress.com/2016/08/04/k-means-document-clustering-using-apache-mahout-command-line/)\n",
    "- [https://bickson.blogspot.com/2011/09/understanding-mahout-k-means-clustering.html](https://bickson.blogspot.com/2011/09/understanding-mahout-k-means-clustering.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Data HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 items\n",
      "-rw-r--r--   3 jfoul001 users     378987 2021-12-31 12:37 dsm010/british-fiction-corpus/ABronte_Agnes.txt\n",
      "-rw-r--r--   3 jfoul001 users     930593 2021-12-31 12:37 dsm010/british-fiction-corpus/ABronte_Tenant.txt\n",
      "-rw-r--r--   3 jfoul001 users     894304 2021-12-31 12:37 dsm010/british-fiction-corpus/Austen_Emma.txt\n",
      "-rw-r--r--   3 jfoul001 users     683758 2021-12-31 12:37 dsm010/british-fiction-corpus/Austen_Pride.txt\n",
      "-rw-r--r--   3 jfoul001 users     678691 2021-12-31 12:37 dsm010/british-fiction-corpus/Austen_Sense.txt\n",
      "-rw-r--r--   3 jfoul001 users    1026320 2021-12-31 12:37 dsm010/british-fiction-corpus/CBronte_Jane.txt\n",
      "-rw-r--r--   3 jfoul001 users     506144 2021-12-31 12:37 dsm010/british-fiction-corpus/CBronte_Professor.txt\n",
      "-rw-r--r--   3 jfoul001 users    1104704 2021-12-31 12:37 dsm010/british-fiction-corpus/CBronte_Villette.txt\n",
      "-rw-r--r--   3 jfoul001 users    1964819 2021-12-31 12:37 dsm010/british-fiction-corpus/Dickens_Bleak.txt\n",
      "-rw-r--r--   3 jfoul001 users    1960784 2021-12-31 12:37 dsm010/british-fiction-corpus/Dickens_David.txt\n",
      "-rw-r--r--   3 jfoul001 users     572724 2021-12-31 12:37 dsm010/british-fiction-corpus/Dickens_Hard.txt\n",
      "-rw-r--r--   3 jfoul001 users     655011 2021-12-31 12:37 dsm010/british-fiction-corpus/EBronte_Wuthering.txt\n",
      "-rw-r--r--   3 jfoul001 users    1169423 2021-12-31 12:37 dsm010/british-fiction-corpus/Eliot_Adam.txt\n",
      "-rw-r--r--   3 jfoul001 users    1803371 2021-12-31 12:37 dsm010/british-fiction-corpus/Eliot_Middlemarch.txt\n",
      "-rw-r--r--   3 jfoul001 users    1158418 2021-12-31 12:37 dsm010/british-fiction-corpus/Eliot_Mill.txt\n",
      "-rw-r--r--   3 jfoul001 users     772698 2021-12-31 12:37 dsm010/british-fiction-corpus/Fielding_Joseph.txt\n",
      "-rw-r--r--   3 jfoul001 users    1961223 2021-12-31 12:37 dsm010/british-fiction-corpus/Fielding_Tom.txt\n",
      "-rw-r--r--   3 jfoul001 users    5263739 2021-12-31 12:37 dsm010/british-fiction-corpus/Richardson_Clarissa.txt\n",
      "-rw-r--r--   3 jfoul001 users    2333073 2021-12-31 12:37 dsm010/british-fiction-corpus/Richardson_Pamela.txt\n",
      "-rw-r--r--   3 jfoul001 users     217007 2021-12-31 12:37 dsm010/british-fiction-corpus/Sterne_Sentimental.txt\n",
      "-rw-r--r--   3 jfoul001 users    1042340 2021-12-31 12:37 dsm010/british-fiction-corpus/Sterne_Tristram.txt\n",
      "-rw-r--r--   3 jfoul001 users     702691 2021-12-31 12:37 dsm010/british-fiction-corpus/Thackeray_Barry.txt\n",
      "-rw-r--r--   3 jfoul001 users    1976584 2021-12-31 12:37 dsm010/british-fiction-corpus/Thackeray_Pendennis.txt\n",
      "-rw-r--r--   3 jfoul001 users    1731407 2021-12-31 12:37 dsm010/british-fiction-corpus/Thackeray_Vanity.txt\n",
      "-rw-r--r--   3 jfoul001 users    1096762 2021-12-31 12:37 dsm010/british-fiction-corpus/Trollope_Barchester.txt\n",
      "-rw-r--r--   3 jfoul001 users    1424627 2021-12-31 12:37 dsm010/british-fiction-corpus/Trollope_Phineas.txt\n",
      "-rw-r--r--   3 jfoul001 users    1531923 2021-12-31 12:37 dsm010/british-fiction-corpus/Trollope_Prime.txt\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 15:08 dsm010/british-fiction-corpus/british-fiction-corpus\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# change to the coursework directory\n",
    "cd ~/code/dsm010-2021-oct/coursework_01/\n",
    "\n",
    "# copy the input documents\n",
    " hadoop fs -copyFromLocal data/raw/western_classics/british-fiction-corpus dsm010/british-fiction-corpus\n",
    "\n",
    "# verify the file uploads\n",
    "hadoop fs -ls dsm010/british-fiction-corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dataset to SequenceFiles\n",
    "\n",
    "SequenceFiles are flat files consisting of binary key/value pairs. Each document is represented as a key-value pair. there the key is the document id and value is its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.\n",
      "Running on hadoop, using /opt/hadoop/current/bin/hadoop and HADOOP_CONF_DIR=/opt/hadoop/current/etc/hadoop\n",
      "MAHOUT-JOB: /opt/mahout/current/mahout-examples-0.13.0-job.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/31 14:53:41 INFO AbstractJob: Command line arguments: {--charset=[UTF-8], --chunkSize=[5], --endPhase=[2147483647], --fileFilterClass=[org.apache.mahout.text.PrefixAdditionFilter], --input=[dsm010/british-fiction-corpus], --keyPrefix=[], --method=[mapreduce], --output=[dsm010/british-fiction-corpus-seqfiles], --startPhase=[0], --tempDir=[temp]}\n",
      "21/12/31 14:53:41 INFO deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir\n",
      "21/12/31 14:53:41 INFO deprecation: mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress\n",
      "21/12/31 14:53:41 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir\n",
      "21/12/31 14:53:42 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 14:53:42 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_226651\n",
      "21/12/31 14:53:42 INFO FileInputFormat: Total input files to process : 27\n",
      "21/12/31 14:53:42 INFO JobSubmitter: number of splits:7\n",
      "21/12/31 14:53:42 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_226651\n",
      "21/12/31 14:53:42 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 14:53:42 INFO Configuration: resource-types.xml not found\n",
      "21/12/31 14:53:42 INFO ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "21/12/31 14:53:43 INFO YarnClientImpl: Submitted application application_1626049283275_226651\n",
      "21/12/31 14:53:43 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_226651/\n",
      "21/12/31 14:53:43 INFO Job: Running job: job_1626049283275_226651\n",
      "21/12/31 14:53:49 INFO Job: Job job_1626049283275_226651 running in uber mode : false\n",
      "21/12/31 14:53:49 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 14:53:55 INFO Job:  map 86% reduce 0%\n",
      "21/12/31 14:53:56 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 14:53:56 INFO Job: Job job_1626049283275_226651 completed successfully\n",
      "21/12/31 14:53:56 INFO Job: Counters: 35\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=1858745\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=35545415\n",
      "\t\tHDFS: Number of bytes written=13527708\n",
      "\t\tHDFS: Number of read operations=154\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=14\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=7\n",
      "\t\tOther local map tasks=2\n",
      "\t\tData-local map tasks=1\n",
      "\t\tRack-local map tasks=4\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=127590\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=25518\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=25518\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=130652160\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=28\n",
      "\t\tMap output records=28\n",
      "\t\tInput split bytes=3290\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=175\n",
      "\t\tCPU time spent (ms)=10400\n",
      "\t\tPhysical memory (bytes) snapshot=2042454016\n",
      "\t\tVirtual memory (bytes) snapshot=44687413248\n",
      "\t\tTotal committed heap usage (bytes)=7369392128\n",
      "\t\tPeak Map Physical memory (bytes)=301842432\n",
      "\t\tPeak Map Virtual memory (bytes)=6389805056\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=13527708\n",
      "21/12/31 14:53:56 INFO MahoutDriver: Program took 14772 ms (Minutes: 0.2462)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mahout seqdirectory -i dsm010/british-fiction-corpus -o dsm010/british-fiction-corpus-seqfiles -c UTF-8 -chunk 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 items\n",
      "-rw-r--r--   3 jfoul001 users          0 2021-12-31 14:53 dsm010/british-fiction-corpus-seqfiles/_SUCCESS\n",
      "-rw-r--r--   3 jfoul001 users    2503651 2021-12-31 14:53 dsm010/british-fiction-corpus-seqfiles/part-m-00000\n",
      "-rw-r--r--   3 jfoul001 users    2277756 2021-12-31 14:53 dsm010/british-fiction-corpus-seqfiles/part-m-00001\n",
      "-rw-r--r--   3 jfoul001 users    2149725 2021-12-31 14:53 dsm010/british-fiction-corpus-seqfiles/part-m-00002\n",
      "-rw-r--r--   3 jfoul001 users    2043774 2021-12-31 14:53 dsm010/british-fiction-corpus-seqfiles/part-m-00003\n",
      "-rw-r--r--   3 jfoul001 users    2026798 2021-12-31 14:53 dsm010/british-fiction-corpus-seqfiles/part-m-00004\n",
      "-rw-r--r--   3 jfoul001 users    1966802 2021-12-31 14:53 dsm010/british-fiction-corpus-seqfiles/part-m-00005\n",
      "-rw-r--r--   3 jfoul001 users     559202 2021-12-31 14:53 dsm010/british-fiction-corpus-seqfiles/part-m-00006\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hadoop fs -ls dsm010/british-fiction-corpus-seqfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert sequenceFiles to sparse vector files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.\n",
      "Running on hadoop, using /opt/hadoop/current/bin/hadoop and HADOOP_CONF_DIR=/opt/hadoop/current/etc/hadoop\n",
      "MAHOUT-JOB: /opt/mahout/current/mahout-examples-0.13.0-job.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/31 15:13:43 INFO SparseVectorsFromSequenceFiles: Maximum n-gram size is: 1\n",
      "21/12/31 15:13:43 INFO SparseVectorsFromSequenceFiles: Minimum LLR value: 1.0\n",
      "21/12/31 15:13:43 INFO SparseVectorsFromSequenceFiles: Number of reduce tasks: 1\n",
      "21/12/31 15:13:43 INFO SparseVectorsFromSequenceFiles: Tokenizing documents in dsm010/british-fiction-corpus-seqfiles\n",
      "21/12/31 15:13:44 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 15:13:44 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_226808\n",
      "21/12/31 15:13:44 INFO FileInputFormat: Total input files to process : 7\n",
      "21/12/31 15:13:44 INFO JobSubmitter: number of splits:7\n",
      "21/12/31 15:13:44 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_226808\n",
      "21/12/31 15:13:44 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 15:13:45 INFO Configuration: resource-types.xml not found\n",
      "21/12/31 15:13:45 INFO ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "21/12/31 15:13:45 INFO YarnClientImpl: Submitted application application_1626049283275_226808\n",
      "21/12/31 15:13:45 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_226808/\n",
      "21/12/31 15:13:45 INFO Job: Running job: job_1626049283275_226808\n",
      "21/12/31 15:13:51 INFO Job: Job job_1626049283275_226808 running in uber mode : false\n",
      "21/12/31 15:13:51 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 15:13:57 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 15:13:57 INFO Job: Job job_1626049283275_226808 completed successfully\n",
      "21/12/31 15:13:57 INFO Job: Counters: 34\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=1855574\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=13528751\n",
      "\t\tHDFS: Number of bytes written=26388375\n",
      "\t\tHDFS: Number of read operations=56\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=14\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=7\n",
      "\t\tData-local map tasks=5\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=122685\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=24537\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=24537\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=125629440\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=28\n",
      "\t\tMap output records=28\n",
      "\t\tInput split bytes=1043\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=333\n",
      "\t\tCPU time spent (ms)=18420\n",
      "\t\tPhysical memory (bytes) snapshot=2569973760\n",
      "\t\tVirtual memory (bytes) snapshot=44691267584\n",
      "\t\tTotal committed heap usage (bytes)=7369392128\n",
      "\t\tPeak Map Physical memory (bytes)=397729792\n",
      "\t\tPeak Map Virtual memory (bytes)=6394085376\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=13527708\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=26388375\n",
      "21/12/31 15:13:57 INFO SparseVectorsFromSequenceFiles: Creating Term Frequency Vectors\n",
      "21/12/31 15:13:57 INFO DictionaryVectorizer: Creating dictionary from dsm010/british-fiction-corpus-vectors/tokenized-documents and saving at dsm010/british-fiction-corpus-vectors/wordcount\n",
      "21/12/31 15:13:57 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 15:13:57 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_226811\n",
      "21/12/31 15:13:57 INFO FileInputFormat: Total input files to process : 7\n",
      "21/12/31 15:13:57 INFO JobSubmitter: number of splits:7\n",
      "21/12/31 15:13:57 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_226811\n",
      "21/12/31 15:13:57 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 15:13:57 INFO YarnClientImpl: Submitted application application_1626049283275_226811\n",
      "21/12/31 15:13:57 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_226811/\n",
      "21/12/31 15:13:57 INFO Job: Running job: job_1626049283275_226811\n",
      "21/12/31 15:14:04 INFO Job: Job job_1626049283275_226811 running in uber mode : false\n",
      "21/12/31 15:14:04 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 15:14:09 INFO Job:  map 14% reduce 0%\n",
      "21/12/31 15:14:10 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 15:14:14 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 15:14:14 INFO Job: Job job_1626049283275_226811 completed successfully\n",
      "21/12/31 15:14:14 INFO Job: Counters: 55\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3044595\n",
      "\t\tFILE: Number of bytes written=8214219\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=26389551\n",
      "\t\tHDFS: Number of bytes written=955129\n",
      "\t\tHDFS: Number of read operations=33\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=7\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=3\n",
      "\t\tRack-local map tasks=4\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=121255\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=9455\n",
      "\t\tTotal time spent by all map tasks (ms)=24251\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1891\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=24251\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1891\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=124165120\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=9681920\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=28\n",
      "\t\tMap output records=318679\n",
      "\t\tMap output bytes=5204855\n",
      "\t\tMap output materialized bytes=3044631\n",
      "\t\tInput split bytes=1176\n",
      "\t\tCombine input records=318679\n",
      "\t\tCombine output records=163944\n",
      "\t\tReduce input groups=57492\n",
      "\t\tReduce shuffle bytes=3044631\n",
      "\t\tReduce input records=163944\n",
      "\t\tReduce output records=38756\n",
      "\t\tSpilled Records=327888\n",
      "\t\tShuffled Maps =7\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=7\n",
      "\t\tGC time elapsed (ms)=363\n",
      "\t\tCPU time spent (ms)=23870\n",
      "\t\tPhysical memory (bytes) snapshot=3601731584\n",
      "\t\tVirtual memory (bytes) snapshot=51177414656\n",
      "\t\tTotal committed heap usage (bytes)=8422162432\n",
      "\t\tPeak Map Physical memory (bytes)=497278976\n",
      "\t\tPeak Map Virtual memory (bytes)=6398296064\n",
      "\t\tPeak Reduce Physical memory (bytes)=403537920\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6424883200\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=26388375\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=955129\n",
      "21/12/31 15:14:14 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 15:14:14 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_226815\n",
      "21/12/31 15:14:14 INFO FileInputFormat: Total input files to process : 7\n",
      "21/12/31 15:14:14 INFO JobSubmitter: number of splits:7\n",
      "21/12/31 15:14:14 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_226815\n",
      "21/12/31 15:14:14 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 15:14:14 INFO YarnClientImpl: Submitted application application_1626049283275_226815\n",
      "21/12/31 15:14:14 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_226815/\n",
      "21/12/31 15:14:14 INFO Job: Running job: job_1626049283275_226815\n",
      "21/12/31 15:14:20 INFO Job: Job job_1626049283275_226815 running in uber mode : false\n",
      "21/12/31 15:14:20 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 15:14:25 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 15:14:33 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 15:14:33 INFO Job: Job job_1626049283275_226815 completed successfully\n",
      "21/12/31 15:14:34 INFO Job: Counters: 55\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=26387254\n",
      "\t\tFILE: Number of bytes written=54913293\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=27189615\n",
      "\t\tHDFS: Number of bytes written=3028543\n",
      "\t\tHDFS: Number of read operations=35\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=7\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=3\n",
      "\t\tRack-local map tasks=4\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=118675\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=23605\n",
      "\t\tTotal time spent by all map tasks (ms)=23735\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4721\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=23735\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4721\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=121523200\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=24171520\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=28\n",
      "\t\tMap output records=28\n",
      "\t\tMap output bytes=26387108\n",
      "\t\tMap output materialized bytes=26387290\n",
      "\t\tInput split bytes=1176\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=27\n",
      "\t\tReduce shuffle bytes=26387290\n",
      "\t\tReduce input records=28\n",
      "\t\tReduce output records=27\n",
      "\t\tSpilled Records=56\n",
      "\t\tShuffled Maps =7\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=7\n",
      "\t\tGC time elapsed (ms)=667\n",
      "\t\tCPU time spent (ms)=23650\n",
      "\t\tPhysical memory (bytes) snapshot=4200214528\n",
      "\t\tVirtual memory (bytes) snapshot=51062484992\n",
      "\t\tTotal committed heap usage (bytes)=9166651392\n",
      "\t\tPeak Map Physical memory (bytes)=534872064\n",
      "\t\tPeak Map Virtual memory (bytes)=6387892224\n",
      "\t\tPeak Reduce Physical memory (bytes)=834416640\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6398664704\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=26388375\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3028543\n",
      "21/12/31 15:14:34 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 15:14:34 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_226819\n",
      "21/12/31 15:14:34 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 15:14:34 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 15:14:34 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_226819\n",
      "21/12/31 15:14:34 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 15:14:34 INFO YarnClientImpl: Submitted application application_1626049283275_226819\n",
      "21/12/31 15:14:34 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_226819/\n",
      "21/12/31 15:14:34 INFO Job: Running job: job_1626049283275_226819\n",
      "21/12/31 15:14:40 INFO Job: Job job_1626049283275_226819 running in uber mode : false\n",
      "21/12/31 15:14:40 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 15:14:45 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 15:14:51 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 15:14:51 INFO Job: Job job_1626049283275_226819 completed successfully\n",
      "21/12/31 15:14:51 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3028037\n",
      "\t\tFILE: Number of bytes written=6587977\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3028709\n",
      "\t\tHDFS: Number of bytes written=3028543\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16240\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16505\n",
      "\t\tTotal time spent by all map tasks (ms)=3248\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3301\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3248\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3301\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16629760\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=16901120\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=27\n",
      "\t\tMap output bytes=3027897\n",
      "\t\tMap output materialized bytes=3028037\n",
      "\t\tInput split bytes=166\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=27\n",
      "\t\tReduce shuffle bytes=3028037\n",
      "\t\tReduce input records=27\n",
      "\t\tReduce output records=27\n",
      "\t\tSpilled Records=54\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=55\n",
      "\t\tCPU time spent (ms)=2800\n",
      "\t\tPhysical memory (bytes) snapshot=703074304\n",
      "\t\tVirtual memory (bytes) snapshot=12772061184\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=393338880\n",
      "\t\tPeak Map Virtual memory (bytes)=6388756480\n",
      "\t\tPeak Reduce Physical memory (bytes)=311214080\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6385270784\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3028543\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3028543\n",
      "21/12/31 15:14:51 INFO HadoopUtil: Deleting dsm010/british-fiction-corpus-vectors/partial-vectors-0\n",
      "21/12/31 15:14:51 INFO SparseVectorsFromSequenceFiles: Calculating IDF\n",
      "21/12/31 15:14:51 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 15:14:51 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_226823\n",
      "21/12/31 15:14:51 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 15:14:51 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 15:14:52 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_226823\n",
      "21/12/31 15:14:52 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 15:14:52 INFO YarnClientImpl: Submitted application application_1626049283275_226823\n",
      "21/12/31 15:14:52 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_226823/\n",
      "21/12/31 15:14:52 INFO Job: Running job: job_1626049283275_226823\n",
      "21/12/31 15:14:58 INFO Job: Job job_1626049283275_226823 running in uber mode : false\n",
      "21/12/31 15:14:58 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 15:15:03 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 15:15:09 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 15:15:09 INFO Job: Job job_1626049283275_226823 completed successfully\n",
      "21/12/31 15:15:09 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=542604\n",
      "\t\tFILE: Number of bytes written=1616211\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3028710\n",
      "\t\tHDFS: Number of bytes written=775373\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17705\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16830\n",
      "\t\tTotal time spent by all map tasks (ms)=3541\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3366\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3541\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3366\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18129920\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17233920\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=286077\n",
      "\t\tMap output bytes=3432924\n",
      "\t\tMap output materialized bytes=542604\n",
      "\t\tInput split bytes=167\n",
      "\t\tCombine input records=286077\n",
      "\t\tCombine output records=38757\n",
      "\t\tReduce input groups=38757\n",
      "\t\tReduce shuffle bytes=542604\n",
      "\t\tReduce input records=38757\n",
      "\t\tReduce output records=38757\n",
      "\t\tSpilled Records=77514\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=34\n",
      "\t\tCPU time spent (ms)=4530\n",
      "\t\tPhysical memory (bytes) snapshot=722636800\n",
      "\t\tVirtual memory (bytes) snapshot=12784807936\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=397295616\n",
      "\t\tPeak Map Virtual memory (bytes)=6386257920\n",
      "\t\tPeak Reduce Physical memory (bytes)=325341184\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6398550016\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3028543\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=775373\n",
      "21/12/31 15:15:09 INFO SparseVectorsFromSequenceFiles: Pruning\n",
      "21/12/31 15:15:09 INFO deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir\n",
      "21/12/31 15:15:09 INFO deprecation: mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress\n",
      "21/12/31 15:15:09 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir\n",
      "21/12/31 15:15:09 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 15:15:09 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_226826\n",
      "21/12/31 15:15:09 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 15:15:09 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 15:15:09 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_226826\n",
      "21/12/31 15:15:09 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 15:15:10 INFO YarnClientImpl: Submitted application application_1626049283275_226826\n",
      "21/12/31 15:15:10 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_226826/\n",
      "21/12/31 15:15:10 INFO Job: Running job: job_1626049283275_226826\n",
      "21/12/31 15:15:16 INFO Job: Job job_1626049283275_226826 running in uber mode : false\n",
      "21/12/31 15:15:16 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 15:15:22 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 15:15:28 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 15:15:28 INFO Job: Job job_1626049283275_226826 completed successfully\n",
      "21/12/31 15:15:28 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1799950\n",
      "\t\tFILE: Number of bytes written=2582411\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3028710\n",
      "\t\tHDFS: Number of bytes written=2680027\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16870\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=18090\n",
      "\t\tTotal time spent by all map tasks (ms)=3374\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3618\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3374\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3618\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17274880\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=18524160\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=27\n",
      "\t\tMap output bytes=3027897\n",
      "\t\tMap output materialized bytes=1024589\n",
      "\t\tInput split bytes=167\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=27\n",
      "\t\tReduce shuffle bytes=1024589\n",
      "\t\tReduce input records=27\n",
      "\t\tReduce output records=27\n",
      "\t\tSpilled Records=54\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=57\n",
      "\t\tCPU time spent (ms)=4520\n",
      "\t\tPhysical memory (bytes) snapshot=759623680\n",
      "\t\tVirtual memory (bytes) snapshot=12797382656\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=379166720\n",
      "\t\tPeak Map Virtual memory (bytes)=6387716096\n",
      "\t\tPeak Reduce Physical memory (bytes)=380456960\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6409666560\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3028543\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2680027\n",
      "21/12/31 15:15:28 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 15:15:28 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_226830\n",
      "21/12/31 15:15:28 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 15:15:28 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 15:15:28 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_226830\n",
      "21/12/31 15:15:28 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 15:15:28 INFO YarnClientImpl: Submitted application application_1626049283275_226830\n",
      "21/12/31 15:15:28 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_226830/\n",
      "21/12/31 15:15:28 INFO Job: Running job: job_1626049283275_226830\n",
      "21/12/31 15:15:34 INFO Job: Job job_1626049283275_226830 running in uber mode : false\n",
      "21/12/31 15:15:34 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 15:15:39 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 15:15:45 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 15:15:45 INFO Job: Job job_1626049283275_226830 completed successfully\n",
      "21/12/31 15:15:45 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2679517\n",
      "\t\tFILE: Number of bytes written=5890067\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2680204\n",
      "\t\tHDFS: Number of bytes written=2680027\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16580\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16090\n",
      "\t\tTotal time spent by all map tasks (ms)=3316\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3218\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3316\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3218\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16977920\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=16476160\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=27\n",
      "\t\tMap output bytes=2679381\n",
      "\t\tMap output materialized bytes=2679517\n",
      "\t\tInput split bytes=177\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=27\n",
      "\t\tReduce shuffle bytes=2679517\n",
      "\t\tReduce input records=27\n",
      "\t\tReduce output records=27\n",
      "\t\tSpilled Records=54\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=52\n",
      "\t\tCPU time spent (ms)=2650\n",
      "\t\tPhysical memory (bytes) snapshot=686395392\n",
      "\t\tVirtual memory (bytes) snapshot=12764573696\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=385929216\n",
      "\t\tPeak Map Virtual memory (bytes)=6378713088\n",
      "\t\tPeak Reduce Physical memory (bytes)=300466176\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6389825536\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680027\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2680027\n",
      "21/12/31 15:15:45 INFO HadoopUtil: Deleting dsm010/british-fiction-corpus-vectors/tf-vectors-partial\n",
      "21/12/31 15:15:45 INFO HadoopUtil: Deleting dsm010/british-fiction-corpus-vectors/tf-vectors-toprune\n",
      "21/12/31 15:15:45 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 15:15:45 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_226834\n",
      "21/12/31 15:15:46 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 15:15:46 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 15:15:46 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_226834\n",
      "21/12/31 15:15:46 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 15:15:46 INFO YarnClientImpl: Submitted application application_1626049283275_226834\n",
      "21/12/31 15:15:46 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_226834/\n",
      "21/12/31 15:15:46 INFO Job: Running job: job_1626049283275_226834\n",
      "21/12/31 15:15:52 INFO Job: Job job_1626049283275_226834 running in uber mode : false\n",
      "21/12/31 15:15:52 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 15:15:57 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 15:16:03 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 15:16:03 INFO Job: Job job_1626049283275_226834 completed successfully\n",
      "21/12/31 15:16:03 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2679517\n",
      "\t\tFILE: Number of bytes written=5893387\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3455539\n",
      "\t\tHDFS: Number of bytes written=2680027\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16565\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16980\n",
      "\t\tTotal time spent by all map tasks (ms)=3313\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3396\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3313\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3396\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16962560\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17387520\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=27\n",
      "\t\tMap output bytes=2679381\n",
      "\t\tMap output materialized bytes=2679517\n",
      "\t\tInput split bytes=159\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=27\n",
      "\t\tReduce shuffle bytes=2679517\n",
      "\t\tReduce input records=27\n",
      "\t\tReduce output records=27\n",
      "\t\tSpilled Records=54\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=51\n",
      "\t\tCPU time spent (ms)=4040\n",
      "\t\tPhysical memory (bytes) snapshot=733880320\n",
      "\t\tVirtual memory (bytes) snapshot=12784246784\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=378384384\n",
      "\t\tPeak Map Virtual memory (bytes)=6377607168\n",
      "\t\tPeak Reduce Physical memory (bytes)=355495936\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6408622080\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680027\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2680027\n",
      "21/12/31 15:16:03 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 15:16:03 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_226837\n",
      "21/12/31 15:16:03 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 15:16:03 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 15:16:03 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_226837\n",
      "21/12/31 15:16:03 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 15:16:04 INFO YarnClientImpl: Submitted application application_1626049283275_226837\n",
      "21/12/31 15:16:04 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_226837/\n",
      "21/12/31 15:16:04 INFO Job: Running job: job_1626049283275_226837\n",
      "21/12/31 15:16:10 INFO Job: Job job_1626049283275_226837 running in uber mode : false\n",
      "21/12/31 15:16:10 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 15:16:15 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 15:16:20 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 15:16:20 INFO Job: Job job_1626049283275_226837 completed successfully\n",
      "21/12/31 15:16:20 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2679517\n",
      "\t\tFILE: Number of bytes written=5890927\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2680193\n",
      "\t\tHDFS: Number of bytes written=2680027\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16155\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=8965\n",
      "\t\tTotal time spent by all map tasks (ms)=3231\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1793\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3231\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1793\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16542720\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=9180160\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=27\n",
      "\t\tMap output bytes=2679381\n",
      "\t\tMap output materialized bytes=2679517\n",
      "\t\tInput split bytes=166\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=27\n",
      "\t\tReduce shuffle bytes=2679517\n",
      "\t\tReduce input records=27\n",
      "\t\tReduce output records=27\n",
      "\t\tSpilled Records=54\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=77\n",
      "\t\tCPU time spent (ms)=2610\n",
      "\t\tPhysical memory (bytes) snapshot=685445120\n",
      "\t\tVirtual memory (bytes) snapshot=12782510080\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=388407296\n",
      "\t\tPeak Map Virtual memory (bytes)=6387785728\n",
      "\t\tPeak Reduce Physical memory (bytes)=297037824\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6395117568\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680027\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2680027\n",
      "21/12/31 15:16:20 INFO HadoopUtil: Deleting dsm010/british-fiction-corpus-vectors/partial-vectors-0\n",
      "21/12/31 15:16:20 INFO MahoutDriver: Program took 156704 ms (Minutes: 2.6117333333333335)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mahout seq2sparse -nv -i dsm010/british-fiction-corpus-seqfiles -o dsm010/british-fiction-corpus-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 items\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 15:15 dsm010/british-fiction-corpus-vectors/df-count\n",
      "-rw-r--r--   3 jfoul001 users     800064 2021-12-31 15:14 dsm010/british-fiction-corpus-vectors/dictionary.file-0\n",
      "-rw-r--r--   3 jfoul001 users     775353 2021-12-31 15:15 dsm010/british-fiction-corpus-vectors/frequency.file-0\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 15:15 dsm010/british-fiction-corpus-vectors/tf-vectors\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 15:16 dsm010/british-fiction-corpus-vectors/tfidf-vectors\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 15:13 dsm010/british-fiction-corpus-vectors/tokenized-documents\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 15:14 dsm010/british-fiction-corpus-vectors/wordcount\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hadoop fs -ls dsm010/british-fiction-corpus-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jfoul001 users          0 2021-12-31 15:15 dsm010/british-fiction-corpus-vectors/tf-vectors/_SUCCESS\n",
      "-rw-r--r--   3 jfoul001 users    2680027 2021-12-31 15:15 dsm010/british-fiction-corpus-vectors/tf-vectors/part-r-00000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hadoop fs -ls dsm010/british-fiction-corpus-vectors/tf-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canopy Clustering\n",
    "\n",
    "To have initial centroids values for the k-means algorithm, run canopy clustering on the TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.\n",
      "Running on hadoop, using /opt/hadoop/current/bin/hadoop and HADOOP_CONF_DIR=/opt/hadoop/current/etc/hadoop\n",
      "MAHOUT-JOB: /opt/mahout/current/mahout-examples-0.13.0-job.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/31 18:13:01 INFO AbstractJob: Command line arguments: {--distanceMeasure=[org.apache.mahout.common.distance.CosineDistanceMeasure], --endPhase=[2147483647], --input=[dsm010/british-fiction-corpus-vectors/tf-vectors], --method=[mapreduce], --output=[dsm010/british-fiction-corpus-canopy-centroids], --overwrite=null, --startPhase=[0], --t1=[0.5], --t2=[0.3], --tempDir=[temp]}\n",
      "21/12/31 18:13:02 INFO CanopyDriver: Build Clusters Input: dsm010/british-fiction-corpus-vectors/tf-vectors Out: dsm010/british-fiction-corpus-canopy-centroids Measure: org.apache.mahout.common.distance.CosineDistanceMeasure@4c08a3e0 t1: 0.5 t2: 0.3\n",
      "21/12/31 18:13:02 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 18:13:02 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_229361\n",
      "21/12/31 18:13:03 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 18:13:03 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 18:13:03 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_229361\n",
      "21/12/31 18:13:03 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 18:13:03 INFO Configuration: resource-types.xml not found\n",
      "21/12/31 18:13:03 INFO ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "21/12/31 18:13:03 INFO YarnClientImpl: Submitted application application_1626049283275_229361\n",
      "21/12/31 18:13:03 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_229361/\n",
      "21/12/31 18:13:03 INFO Job: Running job: job_1626049283275_229361\n",
      "21/12/31 18:13:09 INFO Job: Job job_1626049283275_229361 running in uber mode : false\n",
      "21/12/31 18:13:09 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 18:13:14 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 18:13:20 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 18:13:21 INFO Job: Job job_1626049283275_229361 completed successfully\n",
      "21/12/31 18:13:21 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2749672\n",
      "\t\tFILE: Number of bytes written=6032973\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2680186\n",
      "\t\tHDFS: Number of bytes written=2763394\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17610\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17610\n",
      "\t\tTotal time spent by all map tasks (ms)=3522\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3522\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3522\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3522\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18032640\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=18032640\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=27\n",
      "\t\tMap output bytes=2749536\n",
      "\t\tMap output materialized bytes=2749672\n",
      "\t\tInput split bytes=159\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=2749672\n",
      "\t\tReduce input records=27\n",
      "\t\tReduce output records=26\n",
      "\t\tSpilled Records=54\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=98\n",
      "\t\tCPU time spent (ms)=4320\n",
      "\t\tPhysical memory (bytes) snapshot=731373568\n",
      "\t\tVirtual memory (bytes) snapshot=12773416960\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=406446080\n",
      "\t\tPeak Map Virtual memory (bytes)=6376550400\n",
      "\t\tPeak Reduce Physical memory (bytes)=324927488\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6396866560\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680027\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2763394\n",
      "21/12/31 18:13:21 INFO MahoutDriver: Program took 20034 ms (Minutes: 0.3339)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mahout canopy -i dsm010/british-fiction-corpus-vectors/tf-vectors -ow -o dsm010/british-fiction-corpus-canopy-centroids -dm org.apache.mahout.common.distance.CosineDistanceMeasure -t1 0.5 -t2 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 18:13 dsm010/british-fiction-corpus-canopy-centroids/clusters-0-final\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hadoop fs -ls dsm010/british-fiction-corpus-canopy-centroids/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.\n",
      "Running on hadoop, using /opt/hadoop/current/bin/hadoop and HADOOP_CONF_DIR=/opt/hadoop/current/etc/hadoop\n",
      "MAHOUT-JOB: /opt/mahout/current/mahout-examples-0.13.0-job.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/31 18:23:32 INFO AbstractJob: Command line arguments: {--clustering=null, --clusters=[dsm010/british-fiction-corpus-canopy-centroids], --convergenceDelta=[0.1], --distanceMeasure=[org.apache.mahout.common.distance.CosineDistanceMeasure], --endPhase=[2147483647], --input=[dsm010/british-fiction-corpus-vectors/tf-vectors], --maxIter=[20], --method=[mapreduce], --numClusters=[10], --output=[hdfs://lena/user/jfoul001/dsm010/british-fiction-corpus-kmeans-clusters], --overwrite=null, --startPhase=[0], --tempDir=[temp]}\n",
      "21/12/31 18:23:32 INFO HadoopUtil: Deleting hdfs://lena/user/jfoul001/dsm010/british-fiction-corpus-kmeans-clusters\n",
      "21/12/31 18:23:32 INFO HadoopUtil: Deleting dsm010/british-fiction-corpus-canopy-centroids\n",
      "21/12/31 18:23:33 INFO ZlibFactory: Successfully loaded & initialized native-zlib library\n",
      "21/12/31 18:23:33 INFO CodecPool: Got brand-new compressor [.deflate]\n",
      "21/12/31 18:23:33 INFO RandomSeedGenerator: Wrote 10 Klusters to dsm010/british-fiction-corpus-canopy-centroids/part-randomSeed\n",
      "21/12/31 18:23:33 INFO KMeansDriver: Input: dsm010/british-fiction-corpus-vectors/tf-vectors Clusters In: dsm010/british-fiction-corpus-canopy-centroids/part-randomSeed Out: hdfs://lena/user/jfoul001/dsm010/british-fiction-corpus-kmeans-clusters\n",
      "21/12/31 18:23:33 INFO KMeansDriver: convergence: 0.1 max Iterations: 20\n",
      "21/12/31 18:23:33 INFO CodecPool: Got brand-new decompressor [.deflate]\n",
      "21/12/31 18:23:33 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 18:23:33 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_229517\n",
      "21/12/31 18:23:34 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 18:23:34 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 18:23:34 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_229517\n",
      "21/12/31 18:23:34 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 18:23:34 INFO Configuration: resource-types.xml not found\n",
      "21/12/31 18:23:34 INFO ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "21/12/31 18:23:34 INFO YarnClientImpl: Submitted application application_1626049283275_229517\n",
      "21/12/31 18:23:34 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_229517/\n",
      "21/12/31 18:23:34 INFO Job: Running job: job_1626049283275_229517\n",
      "21/12/31 18:23:40 INFO Job: Job job_1626049283275_229517 running in uber mode : false\n",
      "21/12/31 18:23:40 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 18:23:46 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 18:23:51 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 18:23:52 INFO Job: Job job_1626049283275_229517 completed successfully\n",
      "21/12/31 18:23:52 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=4293685\n",
      "\t\tFILE: Number of bytes written=9119439\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=8988604\n",
      "\t\tHDFS: Number of bytes written=2764438\n",
      "\t\tHDFS: Number of read operations=55\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=18180\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17995\n",
      "\t\tTotal time spent by all map tasks (ms)=3636\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3599\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3636\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3599\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18616320\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=18426880\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=4293629\n",
      "\t\tMap output materialized bytes=4293685\n",
      "\t\tInput split bytes=159\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=4293685\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=20\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=56\n",
      "\t\tCPU time spent (ms)=4930\n",
      "\t\tPhysical memory (bytes) snapshot=720666624\n",
      "\t\tVirtual memory (bytes) snapshot=12775501824\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=404615168\n",
      "\t\tPeak Map Virtual memory (bytes)=6382415872\n",
      "\t\tPeak Reduce Physical memory (bytes)=316051456\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6393085952\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680027\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2764438\n",
      "21/12/31 18:23:52 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 18:23:52 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_229522\n",
      "21/12/31 18:23:53 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 18:23:53 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 18:23:53 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_229522\n",
      "21/12/31 18:23:53 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 18:23:53 INFO YarnClientImpl: Submitted application application_1626049283275_229522\n",
      "21/12/31 18:23:53 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_229522/\n",
      "21/12/31 18:23:53 INFO Job: Running job: job_1626049283275_229522\n",
      "21/12/31 18:23:59 INFO Job: Job job_1626049283275_229522 running in uber mode : false\n",
      "21/12/31 18:23:59 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 18:24:05 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 18:24:10 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 18:24:11 INFO Job: Job job_1626049283275_229522 completed successfully\n",
      "21/12/31 18:24:11 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=6005203\n",
      "\t\tFILE: Number of bytes written=12542475\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=8209450\n",
      "\t\tHDFS: Number of bytes written=2764438\n",
      "\t\tHDFS: Number of read operations=19\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=18645\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17800\n",
      "\t\tTotal time spent by all map tasks (ms)=3729\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3560\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3729\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3560\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=19092480\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=18227200\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=6005147\n",
      "\t\tMap output materialized bytes=6005203\n",
      "\t\tInput split bytes=159\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=6005203\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=20\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=44\n",
      "\t\tCPU time spent (ms)=4580\n",
      "\t\tPhysical memory (bytes) snapshot=742756352\n",
      "\t\tVirtual memory (bytes) snapshot=12781371392\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=424632320\n",
      "\t\tPeak Map Virtual memory (bytes)=6392561664\n",
      "\t\tPeak Reduce Physical memory (bytes)=318124032\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6388809728\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680027\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2764438\n",
      "21/12/31 18:24:11 INFO KMeansDriver: Clustering data\n",
      "21/12/31 18:24:11 INFO KMeansDriver: Running Clustering\n",
      "21/12/31 18:24:11 INFO KMeansDriver: Input: dsm010/british-fiction-corpus-vectors/tf-vectors Clusters In: hdfs://lena/user/jfoul001/dsm010/british-fiction-corpus-kmeans-clusters Out: hdfs://lena/user/jfoul001/dsm010/british-fiction-corpus-kmeans-clusters\n",
      "21/12/31 18:24:11 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 18:24:11 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_229527\n",
      "21/12/31 18:24:11 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 18:24:11 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 18:24:11 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_229527\n",
      "21/12/31 18:24:11 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 18:24:12 INFO YarnClientImpl: Submitted application application_1626049283275_229527\n",
      "21/12/31 18:24:12 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_229527/\n",
      "21/12/31 18:24:12 INFO Job: Running job: job_1626049283275_229527\n",
      "21/12/31 18:24:18 INFO Job: Job job_1626049283275_229527 running in uber mode : false\n",
      "21/12/31 18:24:18 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 18:24:24 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 18:24:24 INFO Job: Job job_1626049283275_229527 completed successfully\n",
      "21/12/31 18:24:24 INFO Job: Counters: 33\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=265775\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=5444818\n",
      "\t\tHDFS: Number of bytes written=2680738\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=18200\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=3640\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3640\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18636800\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=27\n",
      "\t\tInput split bytes=159\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=28\n",
      "\t\tCPU time spent (ms)=2330\n",
      "\t\tPhysical memory (bytes) snapshot=311914496\n",
      "\t\tVirtual memory (bytes) snapshot=6388588544\n",
      "\t\tTotal committed heap usage (bytes)=1052770304\n",
      "\t\tPeak Map Physical memory (bytes)=311914496\n",
      "\t\tPeak Map Virtual memory (bytes)=6388588544\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680027\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2680738\n",
      "21/12/31 18:24:24 INFO MahoutDriver: Program took 52151 ms (Minutes: 0.8691833333333333)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mahout kmeans -i dsm010/british-fiction-corpus-vectors/tf-vectors -c dsm010/british-fiction-corpus-canopy-centroids -o hdfs://lena/user/jfoul001/dsm010/british-fiction-corpus-kmeans-clusters -dm org.apache.mahout.common.distance.CosineDistanceMeasure -cl -cd 0.1 -ow -x 20 -k 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\n",
      "-rw-r--r--   3 jfoul001 users        194 2021-12-31 18:24 dsm010/british-fiction-corpus-kmeans-clusters/_policy\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 18:24 dsm010/british-fiction-corpus-kmeans-clusters/clusteredPoints\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 18:23 dsm010/british-fiction-corpus-kmeans-clusters/clusters-0\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 18:23 dsm010/british-fiction-corpus-kmeans-clusters/clusters-1\n",
      "drwxr-xr-x   - jfoul001 users          0 2021-12-31 18:24 dsm010/british-fiction-corpus-kmeans-clusters/clusters-2-final\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hadoop fs -ls dsm010/british-fiction-corpus-kmeans-clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jfoul001 users          0 2021-12-31 18:24 dsm010/british-fiction-corpus-kmeans-clusters/clusteredPoints/_SUCCESS\n",
      "-rw-r--r--   3 jfoul001 users    2680738 2021-12-31 18:24 dsm010/british-fiction-corpus-kmeans-clusters/clusteredPoints/part-m-00000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hadoop fs -ls dsm010/british-fiction-corpus-kmeans-clusters/clusteredPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   3 jfoul001 users          0 2021-12-31 18:24 dsm010/british-fiction-corpus-kmeans-clusters/clusters-2-final/_SUCCESS\n",
      "-rw-r--r--   3 jfoul001 users        194 2021-12-31 18:24 dsm010/british-fiction-corpus-kmeans-clusters/clusters-2-final/_policy\n",
      "-rw-r--r--   3 jfoul001 users    2764438 2021-12-31 18:24 dsm010/british-fiction-corpus-kmeans-clusters/clusters-2-final/part-r-00000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hadoop fs -ls dsm010/british-fiction-corpus-kmeans-clusters/clusters-2-final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Clustering Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the cluster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.\n",
      "Running on hadoop, using /opt/hadoop/current/bin/hadoop and HADOOP_CONF_DIR=/opt/hadoop/current/etc/hadoop\n",
      "MAHOUT-JOB: /opt/mahout/current/mahout-examples-0.13.0-job.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/31 18:47:33 INFO AbstractJob: Command line arguments: {--dictionary=[dsm010/british-fiction-corpus-vectors/dictionary.file-*], --dictionaryType=[sequencefile], --distanceMeasure=[org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure], --endPhase=[2147483647], --evaluate=null, --input=[dsm010/british-fiction-corpus-kmeans-clusters/clusters-2-final], --numWords=[20], --output=[/home/jfoul001/code/dsm010-2021-oct/coursework_01/data/output/british-fiction-corpus-clusters.txt], --outputFormat=[TEXT], --pointsDir=[dsm010/british-fiction-corpus-kmeans-clusters/clusteredPoints], --startPhase=[0], --substring=[100], --tempDir=[temp]}\n",
      "21/12/31 18:47:35 INFO HadoopUtil: Deleting tmp/representative\n",
      "21/12/31 18:47:35 INFO AbstractJob: Command line arguments: {--clusteredPoints=[dsm010/british-fiction-corpus-kmeans-clusters/clusteredPoints], --distanceMeasure=[org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure], --endPhase=[2147483647], --input=[dsm010/british-fiction-corpus-kmeans-clusters/clusters-2-final], --maxIter=[5], --method=[mapreduce], --output=[tmp/representative], --startPhase=[0], --tempDir=[temp]}\n",
      "21/12/31 18:47:35 INFO RepresentativePointsDriver: Representative Points Iteration 0\n",
      "21/12/31 18:47:35 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 18:47:35 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_229769\n",
      "21/12/31 18:47:35 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 18:47:36 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 18:47:36 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_229769\n",
      "21/12/31 18:47:36 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 18:47:36 INFO Configuration: resource-types.xml not found\n",
      "21/12/31 18:47:36 INFO ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "21/12/31 18:47:36 INFO YarnClientImpl: Submitted application application_1626049283275_229769\n",
      "21/12/31 18:47:36 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_229769/\n",
      "21/12/31 18:47:36 INFO Job: Running job: job_1626049283275_229769\n",
      "21/12/31 18:47:42 INFO Job: Job job_1626049283275_229769 running in uber mode : false\n",
      "21/12/31 18:47:42 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 18:47:47 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 18:47:53 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 18:47:53 INFO Job: Job job_1626049283275_229769 completed successfully\n",
      "21/12/31 18:47:53 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1221703\n",
      "\t\tFILE: Number of bytes written=2975865\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=5922766\n",
      "\t\tHDFS: Number of bytes written=2842735\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17115\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16900\n",
      "\t\tTotal time spent by all map tasks (ms)=3423\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3380\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3423\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3380\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17525760\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17305600\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=1221647\n",
      "\t\tMap output materialized bytes=1221703\n",
      "\t\tInput split bytes=172\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=1221703\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=20\n",
      "\t\tSpilled Records=20\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=34\n",
      "\t\tCPU time spent (ms)=3010\n",
      "\t\tPhysical memory (bytes) snapshot=696336384\n",
      "\t\tVirtual memory (bytes) snapshot=12764962816\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=396759040\n",
      "\t\tPeak Map Virtual memory (bytes)=6382579712\n",
      "\t\tPeak Reduce Physical memory (bytes)=299577344\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6386356224\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680738\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2842735\n",
      "21/12/31 18:47:53 INFO RepresentativePointsDriver: Representative Points Iteration 1\n",
      "21/12/31 18:47:53 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 18:47:53 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_229772\n",
      "21/12/31 18:47:53 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 18:47:53 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 18:47:53 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_229772\n",
      "21/12/31 18:47:53 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 18:47:54 INFO YarnClientImpl: Submitted application application_1626049283275_229772\n",
      "21/12/31 18:47:54 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_229772/\n",
      "21/12/31 18:47:54 INFO Job: Running job: job_1626049283275_229772\n",
      "21/12/31 18:48:00 INFO Job: Job job_1626049283275_229772 running in uber mode : false\n",
      "21/12/31 18:48:00 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 18:48:05 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 18:48:11 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 18:48:11 INFO Job: Job job_1626049283275_229772 completed successfully\n",
      "21/12/31 18:48:11 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1032400\n",
      "\t\tFILE: Number of bytes written=2597259\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=8366380\n",
      "\t\tHDFS: Number of bytes written=3875240\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17015\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16665\n",
      "\t\tTotal time spent by all map tasks (ms)=3403\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3333\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3403\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3333\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17423360\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17064960\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=1032345\n",
      "\t\tMap output materialized bytes=1032400\n",
      "\t\tInput split bytes=172\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=1032400\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=30\n",
      "\t\tSpilled Records=20\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=58\n",
      "\t\tCPU time spent (ms)=3340\n",
      "\t\tPhysical memory (bytes) snapshot=708296704\n",
      "\t\tVirtual memory (bytes) snapshot=12789477376\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=396759040\n",
      "\t\tPeak Map Virtual memory (bytes)=6394249216\n",
      "\t\tPeak Reduce Physical memory (bytes)=311537664\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6395228160\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680738\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3875240\n",
      "21/12/31 18:48:11 INFO RepresentativePointsDriver: Representative Points Iteration 2\n",
      "21/12/31 18:48:11 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 18:48:11 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_229775\n",
      "21/12/31 18:48:11 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 18:48:11 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 18:48:11 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_229775\n",
      "21/12/31 18:48:11 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 18:48:11 INFO YarnClientImpl: Submitted application application_1626049283275_229775\n",
      "21/12/31 18:48:11 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_229775/\n",
      "21/12/31 18:48:11 INFO Job: Running job: job_1626049283275_229775\n",
      "21/12/31 18:48:17 INFO Job: Job job_1626049283275_229775 running in uber mode : false\n",
      "21/12/31 18:48:17 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 18:48:23 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 18:48:29 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 18:48:29 INFO Job: Job job_1626049283275_229775 completed successfully\n",
      "21/12/31 18:48:29 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1154054\n",
      "\t\tFILE: Number of bytes written=2840567\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=10431390\n",
      "\t\tHDFS: Number of bytes written=5029358\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16975\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17560\n",
      "\t\tTotal time spent by all map tasks (ms)=3395\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3512\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3395\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3512\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17382400\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17981440\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=1153998\n",
      "\t\tMap output materialized bytes=1154054\n",
      "\t\tInput split bytes=172\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=1154054\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=40\n",
      "\t\tSpilled Records=20\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=46\n",
      "\t\tCPU time spent (ms)=3430\n",
      "\t\tPhysical memory (bytes) snapshot=682156032\n",
      "\t\tVirtual memory (bytes) snapshot=12774772736\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=398155776\n",
      "\t\tPeak Map Virtual memory (bytes)=6376906752\n",
      "\t\tPeak Reduce Physical memory (bytes)=285548544\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6399361024\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680738\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=5029358\n",
      "21/12/31 18:48:29 INFO RepresentativePointsDriver: Representative Points Iteration 3\n",
      "21/12/31 18:48:29 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 18:48:29 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_229778\n",
      "21/12/31 18:48:29 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 18:48:30 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 18:48:30 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_229778\n",
      "21/12/31 18:48:30 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 18:48:30 INFO YarnClientImpl: Submitted application application_1626049283275_229778\n",
      "21/12/31 18:48:30 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_229778/\n",
      "21/12/31 18:48:30 INFO Job: Running job: job_1626049283275_229778\n",
      "21/12/31 18:48:36 INFO Job: Job job_1626049283275_229778 running in uber mode : false\n",
      "21/12/31 18:48:36 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 18:48:41 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 18:48:47 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 18:48:47 INFO Job: Job job_1626049283275_229778 completed successfully\n",
      "21/12/31 18:48:47 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1123125\n",
      "\t\tFILE: Number of bytes written=2778709\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=12739626\n",
      "\t\tHDFS: Number of bytes written=6152587\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17405\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16990\n",
      "\t\tTotal time spent by all map tasks (ms)=3481\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3398\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3481\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3398\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17822720\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17397760\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=1123069\n",
      "\t\tMap output materialized bytes=1123125\n",
      "\t\tInput split bytes=172\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=1123125\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=50\n",
      "\t\tSpilled Records=20\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=55\n",
      "\t\tCPU time spent (ms)=3750\n",
      "\t\tPhysical memory (bytes) snapshot=715169792\n",
      "\t\tVirtual memory (bytes) snapshot=12766113792\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=404238336\n",
      "\t\tPeak Map Virtual memory (bytes)=6376456192\n",
      "\t\tPeak Reduce Physical memory (bytes)=310931456\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6393622528\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680738\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=6152587\n",
      "21/12/31 18:48:47 INFO RepresentativePointsDriver: Representative Points Iteration 4\n",
      "21/12/31 18:48:47 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 18:48:47 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_229782\n",
      "21/12/31 18:48:47 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 18:48:47 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 18:48:47 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_229782\n",
      "21/12/31 18:48:47 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 18:48:47 INFO YarnClientImpl: Submitted application application_1626049283275_229782\n",
      "21/12/31 18:48:47 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_229782/\n",
      "21/12/31 18:48:47 INFO Job: Running job: job_1626049283275_229782\n",
      "21/12/31 18:48:54 INFO Job: Job job_1626049283275_229782 running in uber mode : false\n",
      "21/12/31 18:48:54 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 18:48:59 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 18:49:05 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 18:49:05 INFO Job: Job job_1626049283275_229782 completed successfully\n",
      "21/12/31 18:49:05 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1068026\n",
      "\t\tFILE: Number of bytes written=2668511\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=14986084\n",
      "\t\tHDFS: Number of bytes written=7220678\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17370\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16800\n",
      "\t\tTotal time spent by all map tasks (ms)=3474\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3360\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3474\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3360\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17786880\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17203200\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=1067971\n",
      "\t\tMap output materialized bytes=1068026\n",
      "\t\tInput split bytes=172\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=1068026\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=60\n",
      "\t\tSpilled Records=20\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=48\n",
      "\t\tCPU time spent (ms)=3950\n",
      "\t\tPhysical memory (bytes) snapshot=759328768\n",
      "\t\tVirtual memory (bytes) snapshot=12756938752\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=436371456\n",
      "\t\tPeak Map Virtual memory (bytes)=6374313984\n",
      "\t\tPeak Reduce Physical memory (bytes)=322957312\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6382624768\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680738\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=7220678\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Scaled Inter-Cluster Density = 0.24540640174678777\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Intra-Cluster Density[0] = 0.5834976196118247\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Intra-Cluster Density[24] = NaN\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Intra-Cluster Density[22] = 0.5089695027443909\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Intra-Cluster Density[11] = NaN\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Intra-Cluster Density[18] = 0.6399932478220899\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Intra-Cluster Density[17] = NaN\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Intra-Cluster Density[14] = 0.5324087672995395\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Intra-Cluster Density[19] = 0.5021463789065704\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Intra-Cluster Density[13] = NaN\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Intra-Cluster Density[9] = 0.4833333333333334\n",
      "21/12/31 18:49:05 INFO ClusterEvaluator: Average Intra-Cluster Density = 0.5417248082862914\n",
      "21/12/31 18:49:06 INFO ClusterDumper: Wrote 10 clusters\n",
      "21/12/31 18:49:06 INFO MahoutDriver: Program took 92961 ms (Minutes: 1.54935)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mahout clusterdump -dt sequencefile \\\n",
    "    -d dsm010/british-fiction-corpus-vectors/dictionary.file-* \\\n",
    "    -i dsm010/british-fiction-corpus-kmeans-clusters/clusters-2-final  \\\n",
    "    -o ~/code/dsm010-2021-oct/coursework_01/data/output/british-fiction-corpus-clusters.txt -b 100 \\\n",
    "    -p dsm010/british-fiction-corpus-kmeans-clusters/clusteredPoints \\\n",
    "    -n 20 --evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Cluster Dump Output\n",
    "\n",
    "The final lines give a statistical evaluation of how good the clustering solution was. You can disregard the CDbw metries. Low inter-cluster density and high intra-cluster density indicates a good solution. The beginning of the file gives representative members (terms) in each cluster, as well as the actual documents in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-Cluster Density: 0.24540640174678777\n",
      "Intra-Cluster Density: 0.5417248082862914\n",
      "CDbw Inter-Cluster Density: 0.0\n",
      "CDbw Intra-Cluster Density: 0.8205571850805228\n",
      "CDbw Separation: 6.966629158888863E8\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tail -n 5 ~/code/dsm010-2021-oct/coursework_01/data/output/british-fiction-corpus-clusters.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Distance Metric: org.apache.mahout.common.distance.CosineDistanceMeasure\n",
      "---- K: 02 -- dsm010/british-fiction-corpus-kmeans/CosineDistanceMeasure/02\n",
      "MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.\n",
      "Running on hadoop, using /opt/hadoop/current/bin/hadoop and HADOOP_CONF_DIR=/opt/hadoop/current/etc/hadoop\n",
      "MAHOUT-JOB: /opt/mahout/current/mahout-examples-0.13.0-job.jar\n",
      "MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.\n",
      "Running on hadoop, using /opt/hadoop/current/bin/hadoop and HADOOP_CONF_DIR=/opt/hadoop/current/etc/hadoop\n",
      "MAHOUT-JOB: /opt/mahout/current/mahout-examples-0.13.0-job.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/31 22:45:02 INFO AbstractJob: Command line arguments: {--clustering=null, --clusters=[dsm010/british-fiction-corpus-canopy-centroids], --convergenceDelta=[0.1], --distanceMeasure=[org.apache.mahout.common.distance.CosineDistanceMeasure], --endPhase=[2147483647], --input=[dsm010/british-fiction-corpus-vectors/tf-vectors], --maxIter=[20], --method=[mapreduce], --numClusters=[2], --output=[hdfs://lena/user/jfoul001/dsm010/british-fiction-corpus-kmeans/CosineDistanceMeasure/02], --overwrite=null, --startPhase=[0], --tempDir=[temp]}\n",
      "21/12/31 22:45:02 INFO HadoopUtil: Deleting dsm010/british-fiction-corpus-canopy-centroids\n",
      "21/12/31 22:45:03 INFO ZlibFactory: Successfully loaded & initialized native-zlib library\n",
      "21/12/31 22:45:03 INFO CodecPool: Got brand-new compressor [.deflate]\n",
      "21/12/31 22:45:03 INFO RandomSeedGenerator: Wrote 2 Klusters to dsm010/british-fiction-corpus-canopy-centroids/part-randomSeed\n",
      "21/12/31 22:45:03 INFO KMeansDriver: Input: dsm010/british-fiction-corpus-vectors/tf-vectors Clusters In: dsm010/british-fiction-corpus-canopy-centroids/part-randomSeed Out: hdfs://lena/user/jfoul001/dsm010/british-fiction-corpus-kmeans/CosineDistanceMeasure/02\n",
      "21/12/31 22:45:03 INFO KMeansDriver: convergence: 0.1 max Iterations: 20\n",
      "21/12/31 22:45:03 INFO CodecPool: Got brand-new decompressor [.deflate]\n",
      "21/12/31 22:45:03 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 22:45:04 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_232034\n",
      "21/12/31 22:45:04 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 22:45:04 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 22:45:04 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_232034\n",
      "21/12/31 22:45:04 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 22:45:04 INFO Configuration: resource-types.xml not found\n",
      "21/12/31 22:45:04 INFO ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "21/12/31 22:45:04 INFO YarnClientImpl: Submitted application application_1626049283275_232034\n",
      "21/12/31 22:45:04 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_232034/\n",
      "21/12/31 22:45:04 INFO Job: Running job: job_1626049283275_232034\n",
      "21/12/31 22:45:10 INFO Job: Job job_1626049283275_232034 running in uber mode : false\n",
      "21/12/31 22:45:10 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 22:45:15 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 22:45:21 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 22:45:22 INFO Job: Job job_1626049283275_232034 completed successfully\n",
      "21/12/31 22:45:22 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1526974\n",
      "\t\tFILE: Number of bytes written=3586113\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4042742\n",
      "\t\tHDFS: Number of bytes written=1300151\n",
      "\t\tHDFS: Number of read operations=23\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17260\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17410\n",
      "\t\tTotal time spent by all map tasks (ms)=3452\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3482\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3452\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3482\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17674240\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17827840\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=1526958\n",
      "\t\tMap output materialized bytes=1526974\n",
      "\t\tInput split bytes=159\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=1526974\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=61\n",
      "\t\tCPU time spent (ms)=3910\n",
      "\t\tPhysical memory (bytes) snapshot=714342400\n",
      "\t\tVirtual memory (bytes) snapshot=12774465536\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=420245504\n",
      "\t\tPeak Map Virtual memory (bytes)=6379855872\n",
      "\t\tPeak Reduce Physical memory (bytes)=294096896\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6394609664\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680027\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1300151\n",
      "21/12/31 22:45:22 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 22:45:22 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_232038\n",
      "21/12/31 22:45:22 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 22:45:22 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 22:45:22 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_232038\n",
      "21/12/31 22:45:22 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 22:45:22 INFO YarnClientImpl: Submitted application application_1626049283275_232038\n",
      "21/12/31 22:45:22 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_232038/\n",
      "21/12/31 22:45:22 INFO Job: Running job: job_1626049283275_232038\n",
      "21/12/31 22:45:28 INFO Job: Job job_1626049283275_232038 running in uber mode : false\n",
      "21/12/31 22:45:28 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 22:45:33 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 22:45:38 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 22:45:38 INFO Job: Job job_1626049283275_232038 completed successfully\n",
      "21/12/31 22:45:38 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2599710\n",
      "\t\tFILE: Number of bytes written=5731585\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=5280876\n",
      "\t\tHDFS: Number of bytes written=1300151\n",
      "\t\tHDFS: Number of read operations=19\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17205\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=9945\n",
      "\t\tTotal time spent by all map tasks (ms)=3441\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1989\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3441\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1989\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17617920\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=10183680\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=2599694\n",
      "\t\tMap output materialized bytes=2599710\n",
      "\t\tInput split bytes=159\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=2599710\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=41\n",
      "\t\tCPU time spent (ms)=3890\n",
      "\t\tPhysical memory (bytes) snapshot=739229696\n",
      "\t\tVirtual memory (bytes) snapshot=12786757632\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=403214336\n",
      "\t\tPeak Map Virtual memory (bytes)=6391304192\n",
      "\t\tPeak Reduce Physical memory (bytes)=336015360\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6395453440\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680027\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1300151\n",
      "21/12/31 22:45:38 INFO KMeansDriver: Clustering data\n",
      "21/12/31 22:45:38 INFO KMeansDriver: Running Clustering\n",
      "21/12/31 22:45:38 INFO KMeansDriver: Input: dsm010/british-fiction-corpus-vectors/tf-vectors Clusters In: hdfs://lena/user/jfoul001/dsm010/british-fiction-corpus-kmeans/CosineDistanceMeasure/02 Out: hdfs://lena/user/jfoul001/dsm010/british-fiction-corpus-kmeans/CosineDistanceMeasure/02\n",
      "21/12/31 22:45:38 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 22:45:39 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_232042\n",
      "21/12/31 22:45:39 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 22:45:39 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 22:45:39 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_232042\n",
      "21/12/31 22:45:39 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 22:45:39 INFO YarnClientImpl: Submitted application application_1626049283275_232042\n",
      "21/12/31 22:45:39 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_232042/\n",
      "21/12/31 22:45:39 INFO Job: Running job: job_1626049283275_232042\n",
      "21/12/31 22:45:45 INFO Job: Job job_1626049283275_232042 running in uber mode : false\n",
      "21/12/31 22:45:45 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 22:45:52 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 22:45:52 INFO Job: Job job_1626049283275_232042 completed successfully\n",
      "21/12/31 22:45:52 INFO Job: Counters: 33\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=265823\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3980531\n",
      "\t\tHDFS: Number of bytes written=2680752\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17545\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=3509\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3509\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17966080\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=27\n",
      "\t\tInput split bytes=159\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=25\n",
      "\t\tCPU time spent (ms)=2270\n",
      "\t\tPhysical memory (bytes) snapshot=306176000\n",
      "\t\tVirtual memory (bytes) snapshot=6387458048\n",
      "\t\tTotal committed heap usage (bytes)=1052770304\n",
      "\t\tPeak Map Physical memory (bytes)=306176000\n",
      "\t\tPeak Map Virtual memory (bytes)=6387458048\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680027\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2680752\n",
      "21/12/31 22:45:52 INFO MahoutDriver: Program took 50479 ms (Minutes: 0.8413166666666667)\n",
      "21/12/31 22:45:58 INFO AbstractJob: Command line arguments: {--dictionary=[dsm010/british-fiction-corpus-vectors/dictionary.file-*], --dictionaryType=[sequencefile], --distanceMeasure=[org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure], --endPhase=[2147483647], --evaluate=null, --input=[dsm010/british-fiction-corpus-kmeans/CosineDistanceMeasure/02/clusters-2-final], --numWords=[20], --output=[/home/jfoul001/code/dsm010-2021-oct/coursework_01/data/output/british-fiction-corpus-clusters/CosineDistanceMeasure/02.txt], --outputFormat=[TEXT], --pointsDir=[dsm010/british-fiction-corpus-kmeans/CosineDistanceMeasure/02/clusteredPoints], --startPhase=[0], --substring=[100], --tempDir=[temp]}\n",
      "21/12/31 22:46:00 INFO HadoopUtil: Deleting tmp/representative\n",
      "21/12/31 22:46:00 INFO AbstractJob: Command line arguments: {--clusteredPoints=[dsm010/british-fiction-corpus-kmeans/CosineDistanceMeasure/02/clusteredPoints], --distanceMeasure=[org.apache.mahout.common.distance.SquaredEuclideanDistanceMeasure], --endPhase=[2147483647], --input=[dsm010/british-fiction-corpus-kmeans/CosineDistanceMeasure/02/clusters-2-final], --maxIter=[5], --method=[mapreduce], --output=[tmp/representative], --startPhase=[0], --tempDir=[temp]}\n",
      "21/12/31 22:46:00 INFO RepresentativePointsDriver: Representative Points Iteration 0\n",
      "21/12/31 22:46:00 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 22:46:00 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_232045\n",
      "21/12/31 22:46:00 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 22:46:00 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 22:46:01 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_232045\n",
      "21/12/31 22:46:01 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 22:46:01 INFO Configuration: resource-types.xml not found\n",
      "21/12/31 22:46:01 INFO ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "21/12/31 22:46:01 INFO YarnClientImpl: Submitted application application_1626049283275_232045\n",
      "21/12/31 22:46:01 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_232045/\n",
      "21/12/31 22:46:01 INFO Job: Running job: job_1626049283275_232045\n",
      "21/12/31 22:46:07 INFO Job: Job job_1626049283275_232045 running in uber mode : false\n",
      "21/12/31 22:46:07 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 22:46:12 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 22:46:18 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 22:46:18 INFO Job: Job job_1626049283275_232045 completed successfully\n",
      "21/12/31 22:46:18 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=284617\n",
      "\t\tFILE: Number of bytes written=1101757\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3980934\n",
      "\t\tHDFS: Number of bytes written=934638\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16655\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16760\n",
      "\t\tTotal time spent by all map tasks (ms)=3331\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3352\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3331\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3352\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17054720\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17162240\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=284601\n",
      "\t\tMap output materialized bytes=284617\n",
      "\t\tInput split bytes=188\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=284617\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=4\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=48\n",
      "\t\tCPU time spent (ms)=2710\n",
      "\t\tPhysical memory (bytes) snapshot=663175168\n",
      "\t\tVirtual memory (bytes) snapshot=12769476608\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=380776448\n",
      "\t\tPeak Map Virtual memory (bytes)=6389993472\n",
      "\t\tPeak Reduce Physical memory (bytes)=284332032\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6383497216\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680752\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=934638\n",
      "21/12/31 22:46:18 INFO RepresentativePointsDriver: Representative Points Iteration 1\n",
      "21/12/31 22:46:18 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 22:46:18 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_232048\n",
      "21/12/31 22:46:18 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 22:46:19 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 22:46:19 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_232048\n",
      "21/12/31 22:46:19 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 22:46:19 INFO YarnClientImpl: Submitted application application_1626049283275_232048\n",
      "21/12/31 22:46:19 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_232048/\n",
      "21/12/31 22:46:19 INFO Job: Running job: job_1626049283275_232048\n",
      "21/12/31 22:46:25 INFO Job: Job job_1626049283275_232048 running in uber mode : false\n",
      "21/12/31 22:46:25 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 22:46:31 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 22:46:36 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 22:46:37 INFO Job: Job job_1626049283275_232048 completed successfully\n",
      "21/12/31 22:46:37 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=198497\n",
      "\t\tFILE: Number of bytes written=929517\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4550216\n",
      "\t\tHDFS: Number of bytes written=1133139\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16825\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16485\n",
      "\t\tTotal time spent by all map tasks (ms)=3365\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3297\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3365\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3297\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17228800\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=16880640\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=198481\n",
      "\t\tMap output materialized bytes=198497\n",
      "\t\tInput split bytes=188\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=198497\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=6\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=62\n",
      "\t\tCPU time spent (ms)=2830\n",
      "\t\tPhysical memory (bytes) snapshot=684314624\n",
      "\t\tVirtual memory (bytes) snapshot=12770717696\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=402792448\n",
      "\t\tPeak Map Virtual memory (bytes)=6395179008\n",
      "\t\tPeak Reduce Physical memory (bytes)=281522176\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6383763456\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680752\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1133139\n",
      "21/12/31 22:46:37 INFO RepresentativePointsDriver: Representative Points Iteration 2\n",
      "21/12/31 22:46:37 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 22:46:37 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_232052\n",
      "21/12/31 22:46:37 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 22:46:37 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 22:46:37 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_232052\n",
      "21/12/31 22:46:37 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 22:46:37 INFO YarnClientImpl: Submitted application application_1626049283275_232052\n",
      "21/12/31 22:46:37 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_232052/\n",
      "21/12/31 22:46:37 INFO Job: Running job: job_1626049283275_232052\n",
      "21/12/31 22:46:43 INFO Job: Job job_1626049283275_232052 running in uber mode : false\n",
      "21/12/31 22:46:43 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 22:46:49 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 22:46:54 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 22:46:55 INFO Job: Job job_1626049283275_232052 completed successfully\n",
      "21/12/31 22:46:55 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=245803\n",
      "\t\tFILE: Number of bytes written=1024129\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4947218\n",
      "\t\tHDFS: Number of bytes written=1378966\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17330\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16725\n",
      "\t\tTotal time spent by all map tasks (ms)=3466\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3345\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3466\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3345\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17745920\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17126400\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=245787\n",
      "\t\tMap output materialized bytes=245803\n",
      "\t\tInput split bytes=188\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=245803\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=8\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=64\n",
      "\t\tCPU time spent (ms)=3050\n",
      "\t\tPhysical memory (bytes) snapshot=685903872\n",
      "\t\tVirtual memory (bytes) snapshot=12773752832\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=401907712\n",
      "\t\tPeak Map Virtual memory (bytes)=6377283584\n",
      "\t\tPeak Reduce Physical memory (bytes)=283996160\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6396473344\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680752\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1378966\n",
      "21/12/31 22:46:55 INFO RepresentativePointsDriver: Representative Points Iteration 3\n",
      "21/12/31 22:46:56 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 22:46:56 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_232056\n",
      "21/12/31 22:46:56 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 22:46:56 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 22:46:56 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_232056\n",
      "21/12/31 22:46:56 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 22:46:56 INFO YarnClientImpl: Submitted application application_1626049283275_232056\n",
      "21/12/31 22:46:56 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_232056/\n",
      "21/12/31 22:46:56 INFO Job: Running job: job_1626049283275_232056\n",
      "21/12/31 22:47:02 INFO Job: Job job_1626049283275_232056 running in uber mode : false\n",
      "21/12/31 22:47:02 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 22:47:08 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 22:47:13 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 22:47:14 INFO Job: Job job_1626049283275_232056 completed successfully\n",
      "21/12/31 22:47:14 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=259759\n",
      "\t\tFILE: Number of bytes written=1052041\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=5438872\n",
      "\t\tHDFS: Number of bytes written=1638749\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16960\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16685\n",
      "\t\tTotal time spent by all map tasks (ms)=3392\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3337\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3392\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3337\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17367040\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=17085440\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=259743\n",
      "\t\tMap output materialized bytes=259759\n",
      "\t\tInput split bytes=188\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=259759\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=53\n",
      "\t\tCPU time spent (ms)=2900\n",
      "\t\tPhysical memory (bytes) snapshot=704098304\n",
      "\t\tVirtual memory (bytes) snapshot=12763881472\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=409669632\n",
      "\t\tPeak Map Virtual memory (bytes)=6384582656\n",
      "\t\tPeak Reduce Physical memory (bytes)=294428672\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6381338624\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680752\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1638749\n",
      "21/12/31 22:47:14 INFO RepresentativePointsDriver: Representative Points Iteration 4\n",
      "21/12/31 22:47:14 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at lena-master/128.86.245.64:8032\n",
      "21/12/31 22:47:14 INFO JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jfoul001/.staging/job_1626049283275_232059\n",
      "21/12/31 22:47:14 INFO FileInputFormat: Total input files to process : 1\n",
      "21/12/31 22:47:14 INFO JobSubmitter: number of splits:1\n",
      "21/12/31 22:47:15 INFO JobSubmitter: Submitting tokens for job: job_1626049283275_232059\n",
      "21/12/31 22:47:15 INFO JobSubmitter: Executing with tokens: []\n",
      "21/12/31 22:47:15 INFO YarnClientImpl: Submitted application application_1626049283275_232059\n",
      "21/12/31 22:47:15 INFO Job: The url to track the job: http://lena-master:8088/proxy/application_1626049283275_232059/\n",
      "21/12/31 22:47:15 INFO Job: Running job: job_1626049283275_232059\n",
      "21/12/31 22:47:21 INFO Job: Job job_1626049283275_232059 running in uber mode : false\n",
      "21/12/31 22:47:21 INFO Job:  map 0% reduce 0%\n",
      "21/12/31 22:47:26 INFO Job:  map 100% reduce 0%\n",
      "21/12/31 22:47:32 INFO Job:  map 100% reduce 100%\n",
      "21/12/31 22:47:32 INFO Job: Job job_1626049283275_232059 completed successfully\n",
      "21/12/31 22:47:32 INFO Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=247360\n",
      "\t\tFILE: Number of bytes written=1027243\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=5958438\n",
      "\t\tHDFS: Number of bytes written=1886133\n",
      "\t\tHDFS: Number of read operations=15\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17020\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16480\n",
      "\t\tTotal time spent by all map tasks (ms)=3404\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3296\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3404\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3296\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17428480\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=16875520\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=27\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=247344\n",
      "\t\tMap output materialized bytes=247360\n",
      "\t\tInput split bytes=188\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=247360\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=12\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=47\n",
      "\t\tCPU time spent (ms)=3300\n",
      "\t\tPhysical memory (bytes) snapshot=693661696\n",
      "\t\tVirtual memory (bytes) snapshot=12763930624\n",
      "\t\tTotal committed heap usage (bytes)=2105540608\n",
      "\t\tPeak Map Physical memory (bytes)=397733888\n",
      "\t\tPeak Map Virtual memory (bytes)=6378684416\n",
      "\t\tPeak Reduce Physical memory (bytes)=295927808\n",
      "\t\tPeak Reduce Virtual memory (bytes)=6385246208\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2680752\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1886133\n",
      "21/12/31 22:47:32 INFO ClusterEvaluator: Scaled Inter-Cluster Density = NaN\n",
      "21/12/31 22:47:32 INFO ClusterEvaluator: Intra-Cluster Density[21] = 0.5927074739481922\n",
      "21/12/31 22:47:32 INFO ClusterEvaluator: Intra-Cluster Density[8] = 0.5806692273302887\n",
      "21/12/31 22:47:32 INFO ClusterEvaluator: Average Intra-Cluster Density = 0.5866883506392404\n",
      "21/12/31 22:47:32 INFO ClusterDumper: Wrote 2 clusters\n",
      "21/12/31 22:47:32 INFO MahoutDriver: Program took 94762 ms (Minutes: 1.5793666666666666)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "\n",
    "# range to use for k\n",
    "k_start=2\n",
    "k_end=2\n",
    "\n",
    "# the path to the vectors, centroids and dictionary\n",
    "path_vectors=dsm010/british-fiction-corpus-vectors/tf-vectors\n",
    "path_centroids=dsm010/british-fiction-corpus-canopy-centroids\n",
    "path_dictionary=dsm010/british-fiction-corpus-vectors/dictionary.file-*\n",
    "\n",
    "# the output base path for the clusters and the result local output path\n",
    "path_hdfs_base=hdfs://lena/user/jfoul001/\n",
    "path_clusters_base=dsm010/british-fiction-corpus-kmeans\n",
    "path_results_base=~/code/dsm010-2021-oct/coursework_01/data/output/british-fiction-corpus-clusters\n",
    "\n",
    "# the distance metric to use\n",
    "#distance_metrics=(\"org.apache.mahout.common.distance.CosineDistanceMeasure\" \"org.apache.mahout.math.algorithms.common.distance.Chebyshev\")\n",
    "distance_metrics=(\"org.apache.mahout.common.distance.CosineDistanceMeasure\")\n",
    "\n",
    "for distance_metric in \"${distance_metrics[@]}\"\n",
    "do\n",
    "  echo \"--- Distance Metric: $distance_metric\"\n",
    "  for ((k = $k_start; k <= $k_end; k++))\n",
    "  do\n",
    "    # get k with a leading zero if required\n",
    "    k_padded=$(printf %02d $k)\n",
    "\n",
    "    # set the output path for the clusters\n",
    "    distance_name=${distance_metric##*.}\n",
    "    path_clusters=\"${path_clusters_base}/${distance_name}/${k_padded}\"\n",
    "\n",
    "    echo \"---- K: $k_padded -- $path_clusters\"\n",
    "\n",
    "    # perform the kmeans clustering\n",
    "    mahout kmeans \\\n",
    "     -i $path_vectors \\\n",
    "     -c $path_centroids \\\n",
    "     -o \"${path_hdfs_base}${path_clusters}\" \\\n",
    "     -dm $distance_metric \\\n",
    "     -cl -cd 0.1 -ow -x 20 \\\n",
    "     -k $k\n",
    "\n",
    "    # set the path for output\n",
    "    path_final_clusters=\"${path_clusters}/clusters-2-final\"\n",
    "    path_clusterpoints=\"${path_clusters}/clusteredPoints\"\n",
    "    path_results=\"${path_results_base}/${distance_name}/${k_padded}.txt\"\n",
    "\n",
    "    # output the cluster results\n",
    "    mahout clusterdump -dt sequencefile \\\n",
    "       -d $path_dictionary \\\n",
    "       -i $path_final_clusters  \\\n",
    "       -o $path_results \\\n",
    "       -b 100 \\\n",
    "       -p $path_clusterpoints \\\n",
    "       -n 20 --evaluate    \n",
    "  done  \n",
    "done"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "429f3e8d45833d845e6e031dbf3e229703adf0bd2129019c99d8da7ba46dd29e"
  },
  "kernelspec": {
   "display_name": "Bash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
